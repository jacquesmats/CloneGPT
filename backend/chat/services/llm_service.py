import os
import requests
from django.conf import settings

class LLMService:
    """
    Service for interacting with Azure OpenAI Language Models.
    
    This service provides methods to communicate with Azure OpenAI API
    for generating AI responses in the chat application. It handles
    the API authentication, request formatting, and error handling.
    """
    
    def __init__(self):
        """
        Initialize the LLM service with Azure OpenAI credentials.
        
        Retrieves API key, endpoint URL, and API version from environment
        variables set in the application's configuration.
        """
        self.api_key = os.environ.get('AZURE_OPENAI_API_KEY')
        self.base_url = os.environ.get('AZURE_OPENAI_ENDPOINT')
        self.api_version = os.environ.get('AZURE_OPENAI_API_VERSION', '2024-10-21')
        
    def generate_response(self, conversation_history, deployment, temperature=0.7):
        """
        Generate a completion response using Azure OpenAI API.
        
        This method sends the conversation messages to Azure OpenAI API
        and returns the generated response. It includes a system message
        to format responses using Markdown.
        
        Args:
            messages (list): List of message dicts with 'role' and 'content' keys
            model (str): The model name/deployment to use for generation
            temperature (float): Controls randomness (0.0 to 1.0)
            
        Returns:
            str: The generated response text
            
        Raises:
            Exception: If there's an error communicating with the API
        """
        try:
            # Construct the full API URL using the provided deployment
            api_url = f"{self.base_url}openai/deployments/{deployment}/chat/completions?api-version={self.api_version}"
            
            # Format the conversation history for the API
            messages = [
                {"role": "system", "content": "Always format your responses using Markdown syntax. Use code blocks with language specification for code, use headings, lists, bold, and other formatting where appropriate."}
            ]
            
            # Add the rest of conversation history
            messages.extend([
                {"role": msg["role"], "content": msg["content"]} 
                for msg in conversation_history
            ])
            
            # Azure OpenAI payload with temperature
            payload = {
                "messages": messages,
                "temperature": temperature,
                "max_tokens": 500
            }
            
            # Azure OpenAI uses a different header for authentication
            headers = {
                "Content-Type": "application/json",
                "api-key": self.api_key
            }
            
            response = requests.post(
                api_url,
                headers=headers,
                json=payload
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                # Log the error for debugging
                print(f"Error from Azure OpenAI API: {response.status_code}, {response.text}")
                return "I'm sorry, I encountered an error generating a response."
                
        except Exception as e:
            # Log the exception
            print(f"Exception in Azure OpenAI service: {str(e)}")
            return "I'm sorry, I encountered an unexpected error."

    def mock_response(self, user_message):
        """
        Generate a mock response for testing without API calls.
        
        This method is useful for development and testing when
        you don't want to make actual API calls to Azure OpenAI.
        
        Args:
            user_message (str): The user's message
            
        Returns:
            str: A mock response that acknowledges the user's message
        """
        return f"This is a mock response to: '{user_message}'. In a production environment, this would be generated by Azure OpenAI."